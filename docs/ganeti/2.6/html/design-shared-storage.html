

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Ganeti shared storage support for 2.3+ &mdash; Ganeti 2.6.2 documentation</title>
    
    <link rel="stylesheet" href="_static/default.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '',
        VERSION:     '2.6.2',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="top" title="Ganeti 2.6.2 documentation" href="index.html" />
    <link rel="next" title="Ganeti CPU Pinning" href="design-cpu-pinning.html" />
    <link rel="prev" title="Moving instances accross node groups" href="design-multi-reloc.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="design-cpu-pinning.html" title="Ganeti CPU Pinning"
             accesskey="N">next</a></li>
        <li class="right" >
          <a href="design-multi-reloc.html" title="Moving instances accross node groups"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">Ganeti 2.6.2 documentation</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="ganeti-shared-storage-support-for-2-3">
<h1><a class="toc-backref" href="#id1">Ganeti shared storage support for 2.3+</a><a class="headerlink" href="#ganeti-shared-storage-support-for-2-3" title="Permalink to this headline">¶</a></h1>
<p>This document describes the changes in Ganeti 2.3+ compared to Ganeti
2.3 storage model.</p>
<div class="contents topic" id="contents">
<p class="topic-title first">Contents</p>
<ul class="simple">
<li><a class="reference internal" href="#ganeti-shared-storage-support-for-2-3" id="id1">Ganeti shared storage support for 2.3+</a><ul>
<li><a class="reference internal" href="#objective" id="id2">Objective</a></li>
<li><a class="reference internal" href="#background" id="id3">Background</a></li>
<li><a class="reference internal" href="#use-cases" id="id4">Use cases</a></li>
<li><a class="reference internal" href="#design-overview" id="id5">Design Overview</a></li>
<li><a class="reference internal" href="#refactoring-of-all-code-referring-to-constants-dts-net-mirror" id="id6">Refactoring of all code referring to constants.DTS_NET_MIRROR</a></li>
<li><a class="reference internal" href="#obsolescence-of-the-primary-secondary-node-model" id="id7">Obsolescence of the primary-secondary node model</a></li>
<li><a class="reference internal" href="#introduction-of-a-shared-file-disk-template" id="id8">Introduction of a shared file disk template</a></li>
<li><a class="reference internal" href="#introduction-of-a-shared-block-device-template" id="id9">Introduction of a shared block device template</a></li>
<li><a class="reference internal" href="#long-term-shared-storage-goals" id="id10">Long-term shared storage goals</a><ul>
<li><a class="reference internal" href="#storage-pool-handling" id="id11">Storage pool handling</a></li>
<li><a class="reference internal" href="#interface-to-the-external-storage-drivers" id="id12">Interface to the external storage drivers</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="objective">
<h2><a class="toc-backref" href="#id2">Objective</a><a class="headerlink" href="#objective" title="Permalink to this headline">¶</a></h2>
<p>The aim is to introduce support for externally mirrored, shared storage.
This includes two distinct disk templates:</p>
<ul class="simple">
<li>A shared filesystem containing instance disks as regular files
typically residing on a networked or cluster filesystem (e.g. NFS,
AFS, Ceph, OCFS2, etc.).</li>
<li>Instance images being shared block devices, typically LUNs residing on
a SAN appliance.</li>
</ul>
</div>
<div class="section" id="background">
<h2><a class="toc-backref" href="#id3">Background</a><a class="headerlink" href="#background" title="Permalink to this headline">¶</a></h2>
<p>DRBD is currently the only shared storage backend supported by Ganeti.
DRBD offers the advantages of high availability while running on
commodity hardware at the cost of high network I/O for block-level
synchronization between hosts. DRBD&#8217;s master-slave model has greatly
influenced Ganeti&#8217;s design, primarily by introducing the concept of
primary and secondary nodes and thus defining an instance&#8217;s “mobility
domain”.</p>
<p>Although DRBD has many advantages, many sites choose to use networked
storage appliances for Virtual Machine hosting, such as SAN and/or NAS,
which provide shared storage without the administrative overhead of DRBD
nor the limitation of a 1:1 master-slave setup. Furthermore, new
distributed filesystems such as Ceph are becoming viable alternatives to
expensive storage appliances. Support for both modes of operation, i.e.
shared block storage and shared file storage backend would make Ganeti a
robust choice for high-availability virtualization clusters.</p>
<p>Throughout this document, the term “externally mirrored storage” will
refer to both modes of shared storage, suggesting that Ganeti does not
need to take care about the mirroring process from one host to another.</p>
</div>
<div class="section" id="use-cases">
<h2><a class="toc-backref" href="#id4">Use cases</a><a class="headerlink" href="#use-cases" title="Permalink to this headline">¶</a></h2>
<p>We consider the following use cases:</p>
<ul class="simple">
<li>A virtualization cluster with FibreChannel shared storage, mapping at
least one LUN per instance, accessible by the whole cluster.</li>
<li>A virtualization cluster with instance images stored as files on an
NFS server.</li>
<li>A virtualization cluster storing instance images on a Ceph volume.</li>
</ul>
</div>
<div class="section" id="design-overview">
<h2><a class="toc-backref" href="#id5">Design Overview</a><a class="headerlink" href="#design-overview" title="Permalink to this headline">¶</a></h2>
<p>The design addresses the following procedures:</p>
<ul class="simple">
<li>Refactoring of all code referring to constants.DTS_NET_MIRROR.</li>
<li>Obsolescence of the primary-secondary concept for externally mirrored
storage.</li>
<li>Introduction of a shared file storage disk template for use with networked
filesystems.</li>
<li>Introduction of shared block device disk template with device
adoption.</li>
</ul>
<p>Additionally, mid- to long-term goals include:</p>
<ul class="simple">
<li>Support for external “storage pools”.</li>
<li>Introduction of an interface for communicating with external scripts,
providing methods for the various stages of a block device&#8217;s and
instance&#8217;s life-cycle. In order to provide storage provisioning
capabilities for various SAN appliances, external helpers in the form
of a “storage driver” will be possibly introduced as well.</li>
</ul>
</div>
<div class="section" id="refactoring-of-all-code-referring-to-constants-dts-net-mirror">
<h2><a class="toc-backref" href="#id6">Refactoring of all code referring to constants.DTS_NET_MIRROR</a><a class="headerlink" href="#refactoring-of-all-code-referring-to-constants-dts-net-mirror" title="Permalink to this headline">¶</a></h2>
<p>Currently, all storage-related decision-making depends on a number of
frozensets in lib/constants.py, typically constants.DTS_NET_MIRROR.
However, constants.DTS_NET_MIRROR is used to signify two different
attributes:</p>
<ul class="simple">
<li>A storage device that is shared</li>
<li>A storage device whose mirroring is supervised by Ganeti</li>
</ul>
<p>We propose the introduction of two new frozensets to ease
decision-making:</p>
<ul class="simple">
<li>constants.DTS_EXT_MIRROR, holding externally mirrored disk templates</li>
<li>constants.DTS_MIRRORED, being a union of constants.DTS_EXT_MIRROR and
DTS_NET_MIRROR.</li>
</ul>
<p>Additionally, DTS_NET_MIRROR will be renamed to DTS_INT_MIRROR to reflect
the status of the storage as internally mirrored by Ganeti.</p>
<p>Thus, checks could be grouped into the following categories:</p>
<ul class="simple">
<li>Mobility checks, like whether an instance failover or migration is
possible should check against constants.DTS_MIRRORED</li>
<li>Syncing actions should be performed only for templates in
constants.DTS_NET_MIRROR</li>
</ul>
</div>
<div class="section" id="obsolescence-of-the-primary-secondary-node-model">
<h2><a class="toc-backref" href="#id7">Obsolescence of the primary-secondary node model</a><a class="headerlink" href="#obsolescence-of-the-primary-secondary-node-model" title="Permalink to this headline">¶</a></h2>
<p>The primary-secondary node concept has primarily evolved through the use
of DRBD. In a globally shared storage framework without need for
external sync (e.g. SAN, NAS, etc.), such a notion does not apply for the
following reasons:</p>
<ol class="arabic simple">
<li>Access to the storage does not necessarily imply different roles for
the nodes (e.g. primary vs secondary).</li>
<li>The same storage is available to potentially more than 2 nodes. Thus,
an instance backed by a SAN LUN for example may actually migrate to
any of the other nodes and not just a pre-designated failover node.</li>
</ol>
<p>The proposed solution is using the iallocator framework for run-time
decision making during migration and failover, for nodes with disk
templates in constants.DTS_EXT_MIRROR. Modifications to gnt-instance and
gnt-node will be required to accept target node and/or iallocator
specification for these operations. Modifications of the iallocator
protocol will be required to address at least the following needs:</p>
<ul class="simple">
<li>Allocation tools must be able to distinguish between internal and
external storage</li>
<li>Migration/failover decisions must take into account shared storage
availability</li>
</ul>
</div>
<div class="section" id="introduction-of-a-shared-file-disk-template">
<h2><a class="toc-backref" href="#id8">Introduction of a shared file disk template</a><a class="headerlink" href="#introduction-of-a-shared-file-disk-template" title="Permalink to this headline">¶</a></h2>
<p>Basic shared file storage support can be implemented by creating a new
disk template based on the existing FileStorage class, with only minor
modifications in lib/bdev.py. The shared file disk template relies on a
shared filesystem (e.g. NFS, AFS, Ceph, OCFS2 over SAN or DRBD) being
mounted on all nodes under the same path, where instance images will be
saved.</p>
<p>A new cluster initialization option is added to specify the mountpoint
of the shared filesystem.</p>
<p>The remainder of this document deals with shared block storage.</p>
</div>
<div class="section" id="introduction-of-a-shared-block-device-template">
<h2><a class="toc-backref" href="#id9">Introduction of a shared block device template</a><a class="headerlink" href="#introduction-of-a-shared-block-device-template" title="Permalink to this headline">¶</a></h2>
<p>Basic shared block device support will be implemented with an additional
disk template. This disk template will not feature any kind of storage
control (provisioning, removal, resizing, etc.), but will instead rely
on the adoption of already-existing block devices (e.g. SAN LUNs, NBD
devices, remote iSCSI targets, etc.).</p>
<p>The shared block device template will make the following assumptions:</p>
<ul class="simple">
<li>The adopted block device has a consistent name across all nodes,
enforced e.g. via udev rules.</li>
<li>The device will be available with the same path under all nodes in the
node group.</li>
</ul>
</div>
<div class="section" id="long-term-shared-storage-goals">
<h2><a class="toc-backref" href="#id10">Long-term shared storage goals</a><a class="headerlink" href="#long-term-shared-storage-goals" title="Permalink to this headline">¶</a></h2>
<div class="section" id="storage-pool-handling">
<h3><a class="toc-backref" href="#id11">Storage pool handling</a><a class="headerlink" href="#storage-pool-handling" title="Permalink to this headline">¶</a></h3>
<p>A new cluster configuration attribute will be introduced, named
“storage_pools”, modeled as a dictionary mapping storage pools to
external storage drivers (see below), e.g.:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="p">{</span>
 <span class="s">&quot;nas1&quot;</span><span class="p">:</span> <span class="s">&quot;foostore&quot;</span><span class="p">,</span>
 <span class="s">&quot;nas2&quot;</span><span class="p">:</span> <span class="s">&quot;foostore&quot;</span><span class="p">,</span>
 <span class="s">&quot;cloud1&quot;</span><span class="p">:</span> <span class="s">&quot;barcloud&quot;</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Ganeti will not interpret the contents of this dictionary, although it
will provide methods for manipulating them under some basic constraints
(pool identifier uniqueness, driver existence). The manipulation of
storage pools will be performed by implementing new options to the
<cite>gnt-cluster</cite> command:</p>
<div class="highlight-python"><pre>gnt-cluster modify --add-pool nas1 foostore
gnt-cluster modify --remove-pool nas1 # There may be no instances using
                                      # the pool to remove it</pre>
</div>
<p>Furthermore, the storage pools will be used to indicate the availability
of storage pools to different node groups, thus specifying the
instances&#8217; “mobility domain”.</p>
<p>New disk templates will also be necessary to facilitate the use of external
storage. The proposed addition is a whole template namespace created by
prefixing the pool names with a fixed string, e.g. “ext:”, forming names
like “ext:nas1”, “ext:foo”.</p>
</div>
<div class="section" id="interface-to-the-external-storage-drivers">
<h3><a class="toc-backref" href="#id12">Interface to the external storage drivers</a><a class="headerlink" href="#interface-to-the-external-storage-drivers" title="Permalink to this headline">¶</a></h3>
<p>In addition to external storage pools, a new interface will be
introduced to allow external scripts to provision and manipulate shared
storage.</p>
<p>In order to provide storage provisioning and manipulation (e.g. growing,
renaming) capabilities, each instance&#8217;s disk template can possibly be
associated with an external “storage driver” which, based on the
instance&#8217;s configuration and tags, will perform all supported storage
operations using auxiliary means (e.g. XML-RPC, ssh, etc.).</p>
<p>A “storage driver” will have to provide the following methods:</p>
<ul class="simple">
<li>Create a disk</li>
<li>Remove a disk</li>
<li>Rename a disk</li>
<li>Resize a disk</li>
<li>Attach a disk to a given node</li>
<li>Detach a disk from a given node</li>
</ul>
<p>The proposed storage driver architecture borrows heavily from the OS
interface and follows a one-script-per-function approach. A storage
driver is expected to provide the following scripts:</p>
<ul class="simple">
<li><cite>create</cite></li>
<li><cite>resize</cite></li>
<li><cite>rename</cite></li>
<li><cite>remove</cite></li>
<li><cite>attach</cite></li>
<li><cite>detach</cite></li>
</ul>
<p>These executables will be called once for each disk with no arguments
and all required information will be passed through environment
variables. The following environment variables will always be present on
each invocation:</p>
<ul class="simple">
<li><cite>INSTANCE_NAME</cite>: The instance&#8217;s name</li>
<li><cite>INSTANCE_UUID</cite>: The instance&#8217;s UUID</li>
<li><cite>INSTANCE_TAGS</cite>: The instance&#8217;s tags</li>
<li><cite>DISK_INDEX</cite>: The current disk index.</li>
<li><cite>LOGICAL_ID</cite>: The disk&#8217;s logical id (if existing)</li>
<li><cite>POOL</cite>: The storage pool the instance belongs to.</li>
</ul>
<p>Additional variables may be available in a per-script context (see
below).</p>
<p>Of particular importance is the disk&#8217;s logical ID, which will act as
glue between Ganeti and the external storage drivers; there are two
possible ways of using a disk&#8217;s logical ID in a storage driver:</p>
<ol class="arabic simple">
<li>Simply use it as a unique identifier (e.g. UUID) and keep a separate,
external database linking it to the actual storage.</li>
<li>Encode all useful storage information in the logical ID and have the
driver decode it at runtime.</li>
</ol>
<p>All scripts should return 0 on success and non-zero on error accompanied by
an appropriate error message on stderr. Furthermore, the following
special cases are defined:</p>
<ol class="arabic">
<li><p class="first"><cite>create</cite> In case of success, a string representing the disk&#8217;s logical
id must be returned on stdout, which will be saved in the instance&#8217;s
configuration and can be later used by the other scripts of the same
storage driver. The logical id may be based on instance name,
instance uuid and/or disk index.</p>
<dl class="docutils">
<dt>Additional environment variables present:</dt>
<dd><ul class="first last simple">
<li><cite>DISK_SIZE</cite>: The requested disk size in MiB</li>
</ul>
</dd>
</dl>
</li>
<li><p class="first"><cite>resize</cite> In case of success, output the new disk size.</p>
<dl class="docutils">
<dt>Additional environment variables present:</dt>
<dd><ul class="first last simple">
<li><cite>DISK_SIZE</cite>: The requested disk size in MiB</li>
</ul>
</dd>
</dl>
</li>
<li><p class="first"><cite>rename</cite> On success, a new logical id should be returned, which will
replace the old one. This script is meant to rename the instance&#8217;s
backing store and update the disk&#8217;s logical ID in case one of them is
bound to the instance name.</p>
<dl class="docutils">
<dt>Additional environment variables present:</dt>
<dd><ul class="first last simple">
<li><cite>NEW_INSTANCE_NAME</cite>: The instance&#8217;s new name.</li>
</ul>
</dd>
</dl>
</li>
</ol>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Ganeti shared storage support for 2.3+</a><ul>
<li><a class="reference internal" href="#objective">Objective</a></li>
<li><a class="reference internal" href="#background">Background</a></li>
<li><a class="reference internal" href="#use-cases">Use cases</a></li>
<li><a class="reference internal" href="#design-overview">Design Overview</a></li>
<li><a class="reference internal" href="#refactoring-of-all-code-referring-to-constants-dts-net-mirror">Refactoring of all code referring to constants.DTS_NET_MIRROR</a></li>
<li><a class="reference internal" href="#obsolescence-of-the-primary-secondary-node-model">Obsolescence of the primary-secondary node model</a></li>
<li><a class="reference internal" href="#introduction-of-a-shared-file-disk-template">Introduction of a shared file disk template</a></li>
<li><a class="reference internal" href="#introduction-of-a-shared-block-device-template">Introduction of a shared block device template</a></li>
<li><a class="reference internal" href="#long-term-shared-storage-goals">Long-term shared storage goals</a><ul>
<li><a class="reference internal" href="#storage-pool-handling">Storage pool handling</a></li>
<li><a class="reference internal" href="#interface-to-the-external-storage-drivers">Interface to the external storage drivers</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="design-multi-reloc.html"
                        title="previous chapter">Moving instances accross node groups</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="design-cpu-pinning.html"
                        title="next chapter">Ganeti CPU Pinning</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="_sources/design-shared-storage.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="design-cpu-pinning.html" title="Ganeti CPU Pinning"
             >next</a></li>
        <li class="right" >
          <a href="design-multi-reloc.html" title="Moving instances accross node groups"
             >previous</a> |</li>
        <li><a href="index.html">Ganeti 2.6.2 documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2006, 2007, 2008, 2009, 2010, 2011, 2012, Google Inc..
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3.
    </div>
  </body>
</html>